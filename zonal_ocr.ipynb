{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to select emplacement of elements to get from a scanned copy\n",
    "\n",
    "As we are screening scanned documents from candidates, it is necessary to convert the pdf into image. Once it is done, it is super useful to indicate our algorithm where he should find the information in order to convert the image to text. If we don't do it, it might add additional work when post-processing the text to capture the required elements for our application.\n",
    "\n",
    "Therefore, we call a widget from matplotlib that indicates the coordinates of the picture where we select our elements. We do this on many documents to ensure the coordinates might takes into account the noise and variability in the way candidates scan their documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final zones: []\n"
     ]
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from PIL import Image\n",
    "\n",
    "# Convert the first page of a PDF to an image\n",
    "pdf_path = \"/Users/gaetanrieben/Desktop/Automation_Work/RH_Lausanne/bulletin-1ere.pdf_24979517.pdf\"  # Replace with your PDF path\n",
    "pages = convert_from_path(pdf_path, dpi=300)\n",
    "first_page = pages[0]\n",
    "\n",
    "# To store rectangle coordinates\n",
    "zones = []\n",
    "\n",
    "# Callback function to capture rectangle coordinates\n",
    "def on_select(eclick, erelease):\n",
    "    \"\"\"\n",
    "    Callback function that gets the coordinates of the rectangle.\n",
    "    :param eclick: Mouse click event (x1, y1)\n",
    "    :param erelease: Mouse release event (x2, y2)\n",
    "    \"\"\"\n",
    "    global zones\n",
    "    x1, y1 = eclick.xdata, eclick.ydata\n",
    "    x2, y2 = erelease.xdata, erelease.ydata\n",
    "    zones.append((min(x1, x2), min(y1, y2), abs(x2 - x1), abs(y2 - y1)))  # (x, y, width, height)\n",
    "    print(f\"Zone: x={min(x1, x2):.0f}, y={min(y1, y2):.0f}, width={abs(x2 - x1):.0f}, height={abs(y2 - y1):.0f}\")\n",
    "\n",
    "# Function to display the image and enable rectangle drawing\n",
    "def define_zones(image):\n",
    "    \"\"\"\n",
    "    Allows the user to draw rectangles interactively on an image.\n",
    "    :param image: PIL.Image object\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(\"Drag to select zones. Close the window when done.\")\n",
    "\n",
    "    # Initialize RectangleSelector\n",
    "    toggle_selector = RectangleSelector(\n",
    "        ax, on_select,\n",
    "        interactive=True  # Enables interactive rectangle drawing\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Call the interactive function\n",
    "define_zones(first_page)\n",
    "\n",
    "# Display final zones\n",
    "print(\"Final zones:\", zones)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the image into text and post-processing text\n",
    "\n",
    "In this step, we are using Tesseract library that does a great job in converting images into text. We could use other library, such as Google Cloud Vision API. I chose this library as it is free.\n",
    "\n",
    "We first define a function that allows us to extract text from images, indicating the image and the region we pre-defined. We will be able to extract text from exact emplacement. \n",
    "\n",
    "Once done, we have to post-process the text we extracted.For instance, the scanned document includes a text in the following format : \" First name and Last Name - Class Number\". We have to remove the elements we are not interest in, and keep everything that is on the left of the \"-\". Then, the last name is the last element, while the first name is element before that last element (In french, we have names such Pierre-David. It's important to keep the whole first name).\n",
    "\n",
    "We have to find for the class level, which is either VP, VG or Gymnase and is indicated in the text written by the school.\n",
    "\n",
    "Lastly, we have a list of classes, and a list of grades. It is highly important to match the right class with the right grade. Otherwise, we might match the wrong grade to a specific class and it will affect the ATS score of that candidate.This is why the subject is in an array, and the grade is in another array, so that we can map it into a dictionary.\n",
    "\n",
    "Those elements are then ready to be transferred into the ATS application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import re\n",
    "\n",
    "\n",
    "# Set the path to the Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = '/opt/homebrew/bin/tesseract'\n",
    "\n",
    "\n",
    "def extract_text_from_region(image, region):\n",
    "    \"\"\"\n",
    "    Extracts text from a specific region of an image using Tesseract OCR.\n",
    "    :param image: PIL.Image object\n",
    "    :param region: Tuple (x, y, width, height) for the ROI\n",
    "    :return: Extracted text\n",
    "    \"\"\"\n",
    "    x, y, width, height = region\n",
    "    left = x\n",
    "    upper = y\n",
    "    right = x + width\n",
    "    lower = y + height\n",
    "    cropped_image = image.crop((left, upper, right, lower))\n",
    "    text = pytesseract.image_to_string(cropped_image)\n",
    "    return text\n",
    "\n",
    "def zonal_ocr_from_pdf(pdf_path, regions):\n",
    "    \"\"\"\n",
    "    Perform zonal OCR on a PDF.\n",
    "    :param pdf_path: Path to the input PDF\n",
    "    :param regions: Dictionary of regions with keys as labels and values as ROI tuples\n",
    "    :return: Extracted data dictionary\n",
    "    \"\"\"\n",
    "    # Convert PDF pages to images\n",
    "    pages = convert_from_path(pdf_path, dpi=300)\n",
    "    extracted_data = {}\n",
    "\n",
    "    for page_number, page_image in enumerate(pages, start=1):\n",
    "        page_data = {}\n",
    "        for label, region in regions.items():\n",
    "            text = extract_text_from_region(page_image, region)\n",
    "            page_data[label] = text.strip()\n",
    "        extracted_data[f'Page_{page_number}'] = page_data\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "def process_grades_and_classes(results):\n",
    "    \"\"\"\n",
    "    Processes the Grades and Classes_Name into separate arrays, removing empty entries.\n",
    "    :param results: Dictionary containing OCR results.\n",
    "    :return: Tuple of arrays (classes_array, grades_array).\n",
    "    \"\"\"\n",
    "    classes_array = []\n",
    "    grades_array = []\n",
    "\n",
    "    for page, data in results.items():\n",
    "        if \"Classes_Name\" in data:\n",
    "            classes_array = [cls for cls in data[\"Classes_Name\"].split('\\n') if cls.strip()]\n",
    "        if \"Grades\" in data:\n",
    "            grades_array = [grade for grade in data[\"Grades\"].split('\\n') if grade.strip()]\n",
    "\n",
    "    return classes_array, grades_array\n",
    "\n",
    "def process_name(results):\n",
    "    \"\"\"\n",
    "    Processes the Name field in the results to split into first name and last name(s).\n",
    "    Updates the results dictionary directly.\n",
    "    :param results: Dictionary containing OCR results.\n",
    "    \"\"\"\n",
    "    for page, data in results.items():\n",
    "        if \"Name\" in data:\n",
    "            name = data[\"Name\"]\n",
    "            # Use regex to remove everything after \"-\" followed by a number\n",
    "            name = re.split(r'\\s*-\\s*\\d', name)[0].strip()\n",
    "            name_parts = name.split()\n",
    "            first_name = name_parts[0]\n",
    "            last_name = \" \".join(name_parts[1:]) if len(name_parts) > 1 else \"\"\n",
    "    return first_name, last_name\n",
    "\n",
    "def process_class_level(results):\n",
    "    \"\"\"\n",
    "    Checks for specific keywords in the Class_Level field and extracts the class level.\n",
    "    Updates the results dictionary directly.\n",
    "    :param results: Dictionary containing OCR results.\n",
    "    \"\"\"\n",
    "    keywords = [\"gymnase\", \"VP\", \"VG\"]\n",
    "    for page, data in results.items():\n",
    "        if \"Class_Level\" in data:\n",
    "            class_level_text = data[\"Class_Level\"].lower()\n",
    "            for keyword in keywords:\n",
    "                if keyword in class_level_text:\n",
    "                    class_level = keyword.upper()\n",
    "                    break\n",
    "\n",
    "    return class_level\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the input PDF\n",
    "    pdf_path = \"/Users/gaetanrieben/Desktop/Automation_Work/RH_Lausanne/bulletin-1ere.pdf_24979517.pdf\"\n",
    "\n",
    "    # Define the regions for Zonal OCR (adjust these coordinates based on your document layout)\n",
    "    # Format: {'label': (x, y, width, height)}\n",
    "    regions = {\n",
    "        \"Classes_Name\": (259, 1188, 1366, 611),  # x, y, width, height based on latest screenshot\n",
    "        \"Name\": (259, 928, 1874, 78),  # x, y, width, height based on latest screenshot\n",
    "        \"Class_Level\": (228, 1006, 2159, 182),  # x, y, width, height based on latest screenshot\n",
    "        \"Grades\": (1643, 1182, 230, 623)  # x, y, width, height based on latest screenshot\n",
    "    }\n",
    "\n",
    "    # Perform Zonal OCR\n",
    "    results = zonal_ocr_from_pdf(pdf_path, regions)\n",
    "\n",
    "        # Process Grades and Classes_Name into arrays\n",
    "    classes_array, grades_array = process_grades_and_classes(results)\n",
    "\n",
    "    first_name, last_name = process_name(results)\n",
    "    class_level = process_class_level(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
